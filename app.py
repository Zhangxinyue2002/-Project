import io
import os
import re
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
import plotly.express as px
import streamlit as st


st.set_page_config(page_title="æ•°æ®åˆ†æä¸å¯è§†åŒ–", page_icon="ğŸ“Š", layout="wide")


@dataclass
class DataSummary:
    rows: int
    cols: int
    missing_total: int
    numeric_cols: List[str]
    categorical_cols: List[str]


def load_file(upload) -> Optional[pd.DataFrame]:
    if upload is None:
        return None

    name = upload.name.lower()
    data = upload.getvalue()

    if name.endswith(".csv"):
        return pd.read_csv(io.BytesIO(data))
    if name.endswith(".xlsx") or name.endswith(".xls"):
        return pd.read_excel(io.BytesIO(data))

    st.error("ä»…æ”¯æŒ CSV / XLSX / XLS æ–‡ä»¶")
    return None


def summarize(df: pd.DataFrame) -> DataSummary:
    numeric_cols = df.select_dtypes(include="number").columns.tolist()
    candidate_cols = df.columns.tolist()
    categorical_cols = []
    first_col = candidate_cols[0] if candidate_cols else None
    for col in candidate_cols:
        series = df[col]
        if str(col).lower().startswith("unnamed"):
            continue
        if series.dtype == "object" or str(series.dtype).startswith("category"):
            categorical_cols.append(col)
            continue
        unique_count = series.nunique(dropna=True)
        if unique_count <= min(50, max(2, len(series) // 20)):
            categorical_cols.append(col)
    if first_col and not str(first_col).lower().startswith("unnamed"):
        if first_col not in categorical_cols:
            categorical_cols.insert(0, first_col)
    return DataSummary(
        rows=len(df),
        cols=len(df.columns),
        missing_total=int(df.isna().sum().sum()),
        numeric_cols=numeric_cols,
        categorical_cols=categorical_cols,
    )


def render_overview(df: pd.DataFrame) -> None:
    summary = summarize(df)

    c1, c2, c3, c4 = st.columns(4)
    c1.metric("è¡Œæ•°", summary.rows)
    c2.metric("åˆ—æ•°", summary.cols)
    c3.metric("ç¼ºå¤±å€¼æ€»æ•°", summary.missing_total)
    c4.metric("æ•°å€¼åˆ—", len(summary.numeric_cols))

    st.subheader("æ•°æ®é¢„è§ˆ")
    st.dataframe(df.head(st.session_state.get("preview_rows", 200)), use_container_width=True)


def safe_sample(df: pd.DataFrame, max_rows: int) -> pd.DataFrame:
    if len(df) <= max_rows:
        return df
    return df.sample(n=max_rows, random_state=42)


def ui_divider() -> None:
    st.markdown("---")


def detect_ftir_structure(df: pd.DataFrame) -> Optional[Dict[str, object]]:
    if df.shape[1] < 5:
        return None
    sample_col = df.columns[0]
    w_cols: List[str] = []
    w_values: List[float] = []
    for col in df.columns[1:]:
        try:
            w_val = float(col)
            w_cols.append(col)
            w_values.append(w_val)
        except (TypeError, ValueError):
            if pd.api.types.is_numeric_dtype(df[col]):
                w_cols.append(col)
                w_values.append(float(len(w_values)))
    if len(w_cols) < 20:
        return None
    order = np.argsort(w_values)[::-1]
    ordered_cols = [w_cols[i] for i in order]
    ordered_vals = [w_values[i] for i in order]
    return {
        "sample_col": sample_col,
        "w_cols": ordered_cols,
        "w_vals": ordered_vals,
    }


def build_long_spectra(df: pd.DataFrame, sample_col: str, w_cols: List[str], w_vals: List[float], samples: List[str]) -> pd.DataFrame:
    sub = df[df[sample_col].isin(samples)][[sample_col] + w_cols].copy()
    sub = sub.melt(id_vars=[sample_col], var_name="wavenumber", value_name="intensity")
    mapper = dict(zip(w_cols, w_vals))
    sub["wavenumber"] = sub["wavenumber"].map(mapper)
    return sub.sort_values("wavenumber", ascending=False)


def smooth_series(values: np.ndarray, window: int) -> np.ndarray:
    if window <= 1:
        return values
    return pd.Series(values).rolling(window=window, center=True, min_periods=1).mean().to_numpy()


def detect_peaks(x: np.ndarray, y: np.ndarray, window: int, min_prom: float, top_n: int) -> pd.DataFrame:
    y_s = smooth_series(y, window)
    peaks: List[Tuple[float, float, float]] = []
    for i in range(1, len(y_s) - 1):
        if y_s[i] > y_s[i - 1] and y_s[i] > y_s[i + 1]:
            left = np.min(y_s[max(0, i - window) : i]) if i - window >= 0 else y_s[i - 1]
            right = np.min(y_s[i + 1 : i + window + 1]) if i + window + 1 <= len(y_s) else y_s[i + 1]
            prominence = y_s[i] - max(left, right)
            if prominence >= min_prom:
                peaks.append((x[i], y[i], y_s[i], prominence))
    if not peaks:
        return pd.DataFrame(columns=["å³°å€¼", "é€è¿‡ç‡", "å¹³æ»‘å¼ºåº¦", "å³°çªå‡ºåº¦"])
    peaks = sorted(peaks, key=lambda t: t[3], reverse=True)[:top_n]
    return pd.DataFrame(peaks, columns=["å³°å€¼", "é€è¿‡ç‡", "å¹³æ»‘å¼ºåº¦", "å³°çªå‡ºåº¦"])


def default_band_mapping() -> pd.DataFrame:
    return pd.DataFrame(
        [
            {"æ³¢æ®µä¸‹é™": 3600, "æ³¢æ®µä¸Šé™": 3200, "å¯¹åº”åŸºå›¢": "O-H ä¼¸ç¼©", "å¯¹åº”æˆåˆ†": "çº¤ç»´ç´ /åŠçº¤ç»´ç´ "},
            {"æ³¢æ®µä¸‹é™": 2970, "æ³¢æ®µä¸Šé™": 2840, "å¯¹åº”åŸºå›¢": "C-H ä¼¸ç¼©", "å¯¹åº”æˆåˆ†": "çº¤ç»´ç´ /æœ¨è´¨ç´ "},
            {"æ³¢æ®µä¸‹é™": 1745, "æ³¢æ®µä¸Šé™": 1710, "å¯¹åº”åŸºå›¢": "C=O ä¼¸ç¼©", "å¯¹åº”æˆåˆ†": "åŠçº¤ç»´ç´ "},
            {"æ³¢æ®µä¸‹é™": 1655, "æ³¢æ®µä¸Šé™": 1590, "å¯¹åº”åŸºå›¢": "èŠ³é¦™ç¯ C=C", "å¯¹åº”æˆåˆ†": "æœ¨è´¨ç´ "},
            {"æ³¢æ®µä¸‹é™": 1515, "æ³¢æ®µä¸Šé™": 1500, "å¯¹åº”åŸºå›¢": "èŠ³é¦™ç¯éª¨æ¶", "å¯¹åº”æˆåˆ†": "æœ¨è´¨ç´ "},
            {"æ³¢æ®µä¸‹é™": 1470, "æ³¢æ®µä¸Šé™": 1410, "å¯¹åº”åŸºå›¢": "CH2 å¼¯æ›²", "å¯¹åº”æˆåˆ†": "çº¤ç»´ç´ "},
            {"æ³¢æ®µä¸‹é™": 1375, "æ³¢æ®µä¸Šé™": 1360, "å¯¹åº”åŸºå›¢": "C-H å¼¯æ›²", "å¯¹åº”æˆåˆ†": "çº¤ç»´ç´ "},
            {"æ³¢æ®µä¸‹é™": 1335, "æ³¢æ®µä¸Šé™": 1310, "å¯¹åº”åŸºå›¢": "O-H å¼¯æ›²", "å¯¹åº”æˆåˆ†": "çº¤ç»´ç´ "},
            {"æ³¢æ®µä¸‹é™": 1275, "æ³¢æ®µä¸Šé™": 1230, "å¯¹åº”åŸºå›¢": "C-O ä¼¸ç¼©", "å¯¹åº”æˆåˆ†": "æœ¨è´¨ç´ /åŠçº¤ç»´ç´ "},
            {"æ³¢æ®µä¸‹é™": 1170, "æ³¢æ®µä¸Šé™": 1120, "å¯¹åº”åŸºå›¢": "C-O-C ä¼¸ç¼©", "å¯¹åº”æˆåˆ†": "çº¤ç»´ç´ "},
            {"æ³¢æ®µä¸‹é™": 1115, "æ³¢æ®µä¸Šé™": 1030, "å¯¹åº”åŸºå›¢": "C-O ä¼¸ç¼©", "å¯¹åº”æˆåˆ†": "çº¤ç»´ç´ /åŠçº¤ç»´ç´ "},
            {"æ³¢æ®µä¸‹é™": 900, "æ³¢æ®µä¸Šé™": 890, "å¯¹åº”åŸºå›¢": "Î²-ç³–è‹·é”®", "å¯¹åº”æˆåˆ†": "çº¤ç»´ç´ "},
        ]
    )


def map_peaks_to_bands(peaks_df: pd.DataFrame, band_df: pd.DataFrame) -> pd.DataFrame:
    rows = []
    for _, row in peaks_df.iterrows():
        peak = float(row["å³°å€¼"])
        match = None
        for _, b in band_df.iterrows():
            low = float(b["æ³¢æ®µä¸‹é™"])
            high = float(b["æ³¢æ®µä¸Šé™"])
            band_min, band_max = min(low, high), max(low, high)
            if band_min <= peak <= band_max:
                match = b
                break
        if match is None:
            band = "æœªçŸ¥"
            group = "æœªçŸ¥"
            comp = "æœªçŸ¥"
        else:
            band = f"{match['æ³¢æ®µä¸‹é™']}-{match['æ³¢æ®µä¸Šé™']}"
            group = match["å¯¹åº”åŸºå›¢"]
            comp = match["å¯¹åº”æˆåˆ†"]
        rows.append(
            {
                "æ³¢æ®µ": band,
                "å³°å€¼": peak,
                "å¯¹åº”åŸºå›¢": group,
                "å¯¹åº”æˆåˆ†": comp,
                "é€è¿‡ç‡": float(row["é€è¿‡ç‡"]),
            }
        )
    return pd.DataFrame(rows)


def parse_sample_code(name: str) -> Tuple[str, Optional[int], Optional[int]]:
    match = re.match(r"^([A-Za-z]+)(\d+)(?:-?(\d+))?$", str(name).strip())
    if not match:
        return str(name), None, None
    prefix = match.group(1).upper()
    series = int(match.group(2)) if match.group(2) else None
    replicate = int(match.group(3)) if match.group(3) else None
    return prefix, series, replicate


def load_sample_metadata(base_dir: str) -> Dict[str, object]:
    path = os.path.join(base_dir, "Sample.xlsx")
    if not os.path.exists(path):
        return {}
    df = pd.read_excel(path, sheet_name=0)
    meta: Dict[str, object] = {}
    if len(df.columns) > 1:
        meta["experiment_text"] = str(df.columns[1])

    sample_map: Dict[str, str] = {}
    if len(df.columns) >= 3:
        col_code = df.columns[1]
        col_desc = df.columns[2]
        for _, row in df.iterrows():
            code = str(row.get(col_code, "")).strip()
            desc = str(row.get(col_desc, "")).strip()
            if re.match(r"^[A-Za-z]{2}\d+", code) and desc:
                prefix = re.match(r"^([A-Za-z]{2})", code).group(1).upper()
                if prefix not in sample_map:
                    sample_map[prefix] = desc
    meta["sample_map"] = sample_map
    return meta


def compute_group_mean(df: pd.DataFrame, sample_col: str, w_cols: List[str], group_keys: List[str]) -> pd.DataFrame:
    grouped = df.groupby(group_keys)[w_cols].mean(numeric_only=True)
    grouped = grouped.reset_index()
    return grouped


st.title("ğŸ“Š æ•°æ®åˆ†æä¸å¯è§†åŒ–ï¼ˆå†…ç½® Pandasï¼‰")

with st.sidebar:
    st.header("å¯¼å…¥æ•°æ®")
    upload = st.file_uploader("é€‰æ‹© CSV æˆ– Excel æ–‡ä»¶", type=["csv", "xlsx", "xls"])
    st.caption("å»ºè®®å…ˆåšåŸºç¡€æ¸…æ´—ï¼šç©ºå€¼ã€å¼‚å¸¸å€¼ã€å­—æ®µç±»å‹")

    ui_divider()
    st.header("æ€§èƒ½ä¸å±•ç¤ºé™åˆ¶")
    preview_rows = st.number_input("é¢„è§ˆè¡Œæ•°ä¸Šé™", min_value=50, max_value=2000, value=200, step=50)
    chart_rows = st.number_input("å›¾è¡¨æœ€å¤§è¡Œæ•°", min_value=200, max_value=200000, value=20000, step=200)
    st.session_state["preview_rows"] = int(preview_rows)
    st.session_state["chart_rows"] = int(chart_rows)

    if st.button("ä½¿ç”¨ç¤ºä¾‹æ•°æ®"):
        sample = pd.DataFrame(
            {
                "æ—¥æœŸ": pd.date_range("2024-01-01", periods=60, freq="D"),
                "ç±»åˆ«": ["A", "B", "C", "D"] * 15,
                "æ•°é‡": [20, 35, 18, 50] * 15,
                "é‡‘é¢": [1200, 1800, 900, 2600] * 15,
            }
        )
        st.session_state["df"] = sample


if upload is not None:
    df = load_file(upload)
    if df is not None:
        st.session_state["df"] = df


df = st.session_state.get("df")

if df is None:
    st.info("è¯·åœ¨å·¦ä¾§ä¸Šä¼ æ–‡ä»¶æˆ–ä½¿ç”¨ç¤ºä¾‹æ•°æ®ã€‚")
    st.stop()

render_overview(df)

ui_divider()

st.subheader("ç»Ÿè®¡æ¦‚è§ˆ")
with st.expander("æè¿°æ€§ç»Ÿè®¡ï¼ˆæ•°å€¼åˆ—ï¼‰", expanded=True):
    numeric_cols = df.select_dtypes(include="number").columns
    if len(numeric_cols) == 0:
        st.warning("æ²¡æœ‰å¯ç”¨çš„æ•°å€¼åˆ—")
    else:
        st.dataframe(df[numeric_cols].describe().T, use_container_width=True)

with st.expander("ç¼ºå¤±å€¼åˆ†å¸ƒ", expanded=False):
    missing = df.isna().sum().sort_values(ascending=False)
    missing = missing[missing > 0]
    if missing.empty:
        st.success("æ— ç¼ºå¤±å€¼")
    else:
        st.dataframe(missing.rename("ç¼ºå¤±æ•°é‡"), use_container_width=True)

ui_divider()

st.subheader("å¯è§†åŒ–")

chart_df = safe_sample(df, st.session_state.get("chart_rows", 20000))
if len(chart_df) < len(df):
    st.info(f"ä¸ºé¿å…æµè§ˆå™¨è¿‡è½½ï¼Œå›¾è¡¨ä»…ä½¿ç”¨æŠ½æ ·æ•°æ®ï¼š{len(chart_df)} è¡Œ / æ€»è®¡ {len(df)} è¡Œã€‚")

summary = summarize(df)

cols = st.columns(2)

with cols[0]:
    st.markdown("**æ•°å€¼åˆ—åˆ†å¸ƒ**")
    num_col = st.selectbox("é€‰æ‹©æ•°å€¼åˆ—", df.select_dtypes(include="number").columns, key="num_col")
    if num_col:
        fig = px.histogram(chart_df, x=num_col, nbins=30, title=f"{num_col} åˆ†å¸ƒ")
        st.plotly_chart(fig, use_container_width=True)

with cols[1]:
    st.markdown("**ç±»åˆ«åˆ—å¯¹æ¯”**")
    cat_col = st.selectbox("é€‰æ‹©ç±»åˆ«åˆ—", summary.categorical_cols, key="cat_col")
    if cat_col:
        vc = chart_df[cat_col].value_counts().reset_index()
        vc.columns = [cat_col, "æ•°é‡"]
        fig = px.bar(vc, x=cat_col, y="æ•°é‡", title=f"{cat_col} é¢‘æ•°")
        st.plotly_chart(fig, use_container_width=True)

ui_divider()

st.subheader("åˆ†ç»„æ±‡æ€»")

group_cols = st.multiselect("é€‰æ‹©åˆ†ç»„åˆ—", df.columns.tolist())
agg_col = st.selectbox("é€‰æ‹©èšåˆåˆ—ï¼ˆæ•°å€¼ï¼‰", df.select_dtypes(include="number").columns, key="agg_col")
agg_func = st.selectbox("èšåˆæ–¹å¼", ["sum", "mean", "median", "count", "min", "max"])

if group_cols and agg_col:
    grouped = chart_df.groupby(group_cols)[agg_col].agg(agg_func).reset_index()
    st.dataframe(grouped, use_container_width=True)

    if len(group_cols) == 1:
        fig = px.bar(grouped, x=group_cols[0], y=agg_col, title="åˆ†ç»„æ±‡æ€»")
        st.plotly_chart(fig, use_container_width=True)

ui_divider()

st.subheader("ç›¸å…³æ€§ï¼ˆæ•°å€¼åˆ—ï¼‰")
num_df = chart_df.select_dtypes(include="number")
if num_df.shape[1] >= 2:
    corr = num_df.corr(numeric_only=True)
    fig = px.imshow(corr, text_auto=True, title="ç›¸å…³çŸ©é˜µ")
    st.plotly_chart(fig, use_container_width=True)
else:
    st.info("æ•°å€¼åˆ—ä¸è¶³ï¼Œæ— æ³•è®¡ç®—ç›¸å…³æ€§ã€‚")

ui_divider()

st.subheader("FTIR ä¸“ç”¨åˆ†æ")
ftir = detect_ftir_structure(df)
meta = load_sample_metadata(os.path.dirname(__file__))
if not ftir:
    st.info("æœªæ£€æµ‹åˆ°å…¸å‹ FTIR ç»“æ„ï¼ˆé¦–åˆ—æ ·æœ¬å + å¤§é‡æ³¢æ•°åˆ—ï¼‰ã€‚")
else:
    sample_col = ftir["sample_col"]
    w_cols = ftir["w_cols"]
    w_vals = ftir["w_vals"]

    df_ftir = df.copy()
    df_ftir[sample_col] = df_ftir[sample_col].astype(str)
    df_ftir["_prefix"], df_ftir["_series"], df_ftir["_replicate"] = zip(
        *df_ftir[sample_col].map(parse_sample_code)
    )
    all_samples = df_ftir[sample_col].dropna().unique().tolist()
    default_samples = all_samples[: min(5, len(all_samples))]

    if meta.get("experiment_text"):
        with st.expander("å®éªŒè¯´æ˜ï¼ˆæ¥è‡ª Sample.xlsxï¼‰", expanded=False):
            st.write(meta["experiment_text"])

    with st.expander("FTIR æ³¢æ®µ-åŸºå›¢æ˜ å°„", expanded=False):
        if "band_map" not in st.session_state:
            st.session_state["band_map"] = default_band_mapping()
        band_df = st.data_editor(
            st.session_state["band_map"],
            num_rows="dynamic",
            use_container_width=True,
        )
        st.session_state["band_map"] = band_df

    with st.expander("è°±çº¿ç»˜åˆ¶ï¼ˆå•æ ·æœ¬/å¤šæ ·æœ¬ï¼‰", expanded=True):
        pick_samples = st.multiselect("é€‰æ‹©æ ·æœ¬", all_samples, default=default_samples, key="ftir_samples")
        step = st.number_input("æ¯éš” N ä¸ªæ³¢æ•°å–ç‚¹", min_value=1, max_value=20, value=1, step=1)
        if pick_samples:
            w_cols_step = w_cols[:: int(step)]
            w_vals_step = w_vals[:: int(step)]
            long_df = build_long_spectra(df_ftir, sample_col, w_cols_step, w_vals_step, pick_samples)
            fig = px.line(long_df, x="wavenumber", y="intensity", color=sample_col, title="æ ·æœ¬è°±çº¿")
            fig.update_xaxes(autorange="reversed")
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ ·æœ¬")

    with st.expander("å¹³å‡è°±", expanded=False):
        avg_samples = st.multiselect("é€‰æ‹©ç”¨äºå¹³å‡çš„æ ·æœ¬", all_samples, default=default_samples, key="ftir_avg_samples")
        if avg_samples:
            sub = df_ftir[df_ftir[sample_col].isin(avg_samples)][w_cols].copy()
            avg = sub.mean(axis=0, skipna=True).to_numpy()
            avg_df = pd.DataFrame({"wavenumber": w_vals, "intensity": avg}).sort_values("wavenumber", ascending=False)
            fig = px.line(avg_df, x="wavenumber", y="intensity", title="å¹³å‡è°±")
            fig.update_xaxes(autorange="reversed")
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ ·æœ¬")

    with st.expander("å·®å¼‚è°±ï¼ˆæ ·æœ¬ - å‚è€ƒï¼‰", expanded=False):
        ref_sample = st.selectbox("å‚è€ƒæ ·æœ¬", all_samples, index=0, key="ftir_ref")
        diff_samples = st.multiselect("å¯¹æ¯”æ ·æœ¬", all_samples, default=default_samples, key="ftir_diff_samples")
        if ref_sample and diff_samples:
            ref_row = df_ftir[df_ftir[sample_col] == ref_sample][w_cols].iloc[0].to_numpy()
            rows = []
            for s in diff_samples:
                target = df_ftir[df_ftir[sample_col] == s][w_cols].iloc[0].to_numpy()
                diff = target - ref_row
                rows.append(pd.DataFrame({"wavenumber": w_vals, "intensity": diff, "æ ·æœ¬": s}))
            diff_df = pd.concat(rows, ignore_index=True).sort_values("wavenumber", ascending=False)
            fig = px.line(diff_df, x="wavenumber", y="intensity", color="æ ·æœ¬", title="å·®å¼‚è°±")
            fig.update_xaxes(autorange="reversed")
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("è¯·é€‰æ‹©å‚è€ƒæ ·æœ¬å’Œè‡³å°‘ä¸€ä¸ªå¯¹æ¯”æ ·æœ¬")

    with st.expander("å³°ä½æ£€æµ‹", expanded=False):
        peak_mode = st.selectbox("å³°ä½æ¥æº", ["å•ä¸€æ ·æœ¬", "å¹³å‡è°±"], index=0)
        peak_sample = st.selectbox("é€‰æ‹©æ ·æœ¬", all_samples, index=0, key="ftir_peak_sample")
        smooth_window = st.number_input("å¹³æ»‘çª—å£", min_value=1, max_value=31, value=5, step=2)
        if peak_mode == "å¹³å‡è°±":
            avg_samples = st.multiselect("é€‰æ‹©ç”¨äºå¹³å‡çš„æ ·æœ¬", all_samples, default=default_samples, key="ftir_peak_avg")
            if avg_samples:
                y_vals = df_ftir[df_ftir[sample_col].isin(avg_samples)][w_cols].mean(axis=0, skipna=True).to_numpy()
            else:
                y_vals = df_ftir[df_ftir[sample_col] == peak_sample][w_cols].iloc[0].to_numpy()
        else:
            y_vals = df_ftir[df_ftir[sample_col] == peak_sample][w_cols].iloc[0].to_numpy()
        prom_max = float(np.nanmax(y_vals) - np.nanmin(y_vals))
        prom_max = prom_max if prom_max > 0 else 0.01
        min_prom = st.slider("æœ€å°å³°çªå‡ºåº¦", min_value=0.0, max_value=prom_max, value=min(0.001, prom_max), step=0.001)
        top_n = st.number_input("è¿”å›å³°æ•°é‡", min_value=5, max_value=50, value=15, step=1)
        peaks_df = detect_peaks(np.array(w_vals), y_vals, int(smooth_window), float(min_prom), int(top_n))
        st.dataframe(peaks_df, use_container_width=True)

        band_df = st.session_state.get("band_map", default_band_mapping())
        result_df = map_peaks_to_bands(peaks_df, band_df)
        st.markdown("**FTIR å³°è¡¨ï¼ˆæ³¢æ®µ / å³°å€¼ / åŸºå›¢ / æˆåˆ† / é€è¿‡ç‡ï¼‰**")
        st.dataframe(result_df, use_container_width=True)
        st.download_button(
            "ä¸‹è½½å³°è¡¨ CSV",
            data=result_df.to_csv(index=False).encode("utf-8-sig"),
            file_name="ftir_peaks.csv",
            mime="text/csv",
        )

    with st.expander("åˆ†ç»„å¹³å‡è°±ä¸å·®å¼‚", expanded=False):
        group_mode = st.selectbox("åˆ†ç»„æ–¹å¼", ["æ ·æœ¬å‰ç¼€ (LB/LD/SS/SR)", "ç³»åˆ—ç¼–å· (1/2/3/4)"], index=0)
        if group_mode.startswith("æ ·æœ¬å‰ç¼€"):
            group_key = "_prefix"
        else:
            group_key = "_series"
        grouped = compute_group_mean(df_ftir, sample_col, w_cols, [group_key])
        group_vals = grouped[group_key].dropna().astype(str).tolist()
        selected_groups = st.multiselect("é€‰æ‹©å¯¹æ¯”ç»„", group_vals, default=group_vals[: min(4, len(group_vals))])
        if selected_groups:
            rows = []
            for g in selected_groups:
                row = grouped[grouped[group_key].astype(str) == str(g)][w_cols].iloc[0].to_numpy()
                rows.append(pd.DataFrame({"wavenumber": w_vals, "intensity": row, "ç»„åˆ«": str(g)}))
            gdf = pd.concat(rows, ignore_index=True).sort_values("wavenumber", ascending=False)
            fig = px.line(gdf, x="wavenumber", y="intensity", color="ç»„åˆ«", title="åˆ†ç»„å¹³å‡è°±")
            fig.update_xaxes(autorange="reversed")
            st.plotly_chart(fig, use_container_width=True)

            if len(selected_groups) >= 2:
                base = selected_groups[0]
                base_row = grouped[grouped[group_key].astype(str) == str(base)][w_cols].iloc[0].to_numpy()
                diff_rows = []
                for g in selected_groups[1:]:
                    row = grouped[grouped[group_key].astype(str) == str(g)][w_cols].iloc[0].to_numpy()
                    diff_rows.append(pd.DataFrame({"wavenumber": w_vals, "intensity": row - base_row, "ç»„åˆ«": f"{g}-vs-{base}"}))
                diff_df = pd.concat(diff_rows, ignore_index=True).sort_values("wavenumber", ascending=False)
                fig = px.line(diff_df, x="wavenumber", y="intensity", color="ç»„åˆ«", title="ç»„é—´å·®å¼‚è°±")
                fig.update_xaxes(autorange="reversed")
                st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªç»„")

ui_divider()

st.subheader("è‡ªåŠ¨åˆ†ææ‘˜è¦")
if ftir:
    summary_lines = []
    summary_lines.append(f"æ£€æµ‹åˆ° FTIR ç»“æ„ï¼šæ ·æœ¬åˆ—ä¸º {ftir['sample_col']}ï¼Œæ³¢æ•°åˆ—çº¦ {len(ftir['w_cols'])} ä¸ªã€‚")

    if meta.get("sample_map"):
        maps = meta["sample_map"]
        mapped = ", ".join([f"{k}: {v}" for k, v in maps.items()])
        summary_lines.append(f"æ ·æœ¬å‰ç¼€å«ä¹‰ï¼š{mapped}ã€‚")

    if meta.get("experiment_text"):
        summary_lines.append("å®éªŒé‡‡ç”¨è¶…å£°æ³¢è¾…åŠ©ç¢±æµ¸å‡ºå¤„ç†ï¼Œå˜é‡åŒ…æ‹¬æ—¶é—´ã€æ¶²å›ºæ¯”ã€NaOH æµ“åº¦ä¸æ¸©åº¦ã€‚")

    if "ftir_samples" in st.session_state and st.session_state["ftir_samples"]:
        used_samples = st.session_state["ftir_samples"]
        summary_lines.append(f"å·²é€‰æ‹© {len(used_samples)} ä¸ªæ ·æœ¬ç”¨äºè°±çº¿å±•ç¤ºï¼š{', '.join(used_samples[:5])}{'â€¦' if len(used_samples)>5 else ''}ã€‚")

    if "ftir_avg_samples" in st.session_state and st.session_state["ftir_avg_samples"]:
        avg_samples = st.session_state["ftir_avg_samples"]
        summary_lines.append(f"å¹³å‡è°±åŸºäº {len(avg_samples)} ä¸ªæ ·æœ¬ã€‚")

    if "ftir_peak_sample" in st.session_state:
        peak_sample = st.session_state["ftir_peak_sample"]
        y_vals = df_ftir[df_ftir[ftir["sample_col"]] == peak_sample][ftir["w_cols"]].iloc[0].to_numpy()
        peaks_df = detect_peaks(np.array(ftir["w_vals"]), y_vals, 5, 0.001, 10)
        if not peaks_df.empty:
            top_peaks = ", ".join([f"{row['å³°å€¼']:.1f}" for _, row in peaks_df.head(5).iterrows()])
            summary_lines.append(f"æ ·æœ¬ {peak_sample} çš„ä¸»è¦å³°ä½ï¼ˆå‰ 5ï¼‰ï¼š{top_peaks}ã€‚")

    # Variability across all samples
    matrix = df_ftir[ftir["w_cols"]].to_numpy(dtype=float)
    variance = np.nanvar(matrix, axis=0)
    top_var_idx = np.argsort(variance)[-8:][::-1]
    var_points = ", ".join([f"{ftir['w_vals'][i]:.1f}" for i in top_var_idx])
    summary_lines.append(f"å…¨æ ·æœ¬å˜åŒ–è¾ƒå¤§çš„æ³¢æ•°ç‚¹ï¼ˆå‰ 8ï¼‰ï¼š{var_points}ã€‚")

    # Group differences by prefix
    grouped = compute_group_mean(df_ftir, ftir["sample_col"], ftir["w_cols"], ["_prefix"])
    if len(grouped) >= 2:
        group_names = grouped["_prefix"].astype(str).tolist()
        distances = []
        for i in range(len(group_names)):
            for j in range(i + 1, len(group_names)):
                a = grouped.iloc[i][ftir["w_cols"]].to_numpy(dtype=float)
                b = grouped.iloc[j][ftir["w_cols"]].to_numpy(dtype=float)
                dist = float(np.nanmean(np.abs(a - b)))
                distances.append((group_names[i], group_names[j], dist))
        distances.sort(key=lambda t: t[2], reverse=True)
        g1, g2, dist = distances[0]
        summary_lines.append(f"ç»„é—´å¹³å‡è°±å·®å¼‚æœ€å¤§ï¼š{g1} vs {g2}ï¼ˆå¹³å‡ç»å¯¹å·® {dist:.4g}ï¼‰ã€‚")
        summary_lines.append("æ¨æµ‹ï¼šè¿™äº›ç»„åˆ«åœ¨åŒ–å­¦ç»„æˆæˆ–æ‚è´¨å»é™¤ç¨‹åº¦ä¸Šå¯èƒ½å­˜åœ¨å·®å¼‚ï¼Œéœ€ç»“åˆå·¥è‰ºå‚æ•°éªŒè¯ã€‚")

    st.write("\n".join([f"â€¢ {line}" for line in summary_lines]) if summary_lines else "æš‚æ— å¯æ€»ç»“çš„ç»“æœã€‚")
else:
    st.info("å½“å‰æ•°æ®ä¸æ»¡è¶³ FTIR ç»“æ„ï¼Œæ— æ³•è‡ªåŠ¨æ€»ç»“ã€‚")
